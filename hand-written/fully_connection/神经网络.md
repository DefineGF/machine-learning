#### Node

##### 属性

- layer_index：节点所在层索引
- node_index：节点在层中的索引
- downstream：与上游的节点的连接 列表
- upstream：与下游的节点的连接 列表
- output：节点输出值
- delta：节点误差项



##### 核心方法

- append_downstream_connection：添加一个到下游节点的连接

- append_upstream_connection：添加一个到上游节点的连接
- calc_output：计算节点输出
- calc_hidden_layer_delta：计算 隐藏层 误差项
- calc_output_layer_delta：计算 输出层 误差项



####  ConstNode

便于偏置项计算

##### 属性

- layer_index：节点所属的层的索引
- node_index：节点在层中的索引

- downstream：下游连接列表



#### Layer

##### 属性

- layer_index：层编号
- nodes：当前层的节点列表

##### 核心方法

- init：初始层、添加该层节点 & ConstNode
- calc_output：迭代调用 node 的 calc_output 方法
- set_output：迭代调用 node 的 set_output方法



#### Connection

##### 属性

- upstream_node：上游节点
- downstream_node：下游节点
- weight：权重
- gradient：梯度，用于更新权重

##### 核心方法

- calc_gradient：计算梯度：下游节点误差项 * 上游输出
- update_weight：更新权重：权重<sub>new</sub>  <- 权重<sub>old</sub> + 学习率 * 梯度



#### Connections

##### 属性

- connections：连接的列表



#### Network

#####  属性

- connections：所有连接
- layers：所有层



##### 核心方法

- init：传入各层节点数，list

    - 根据各层节点数初始化各层；
    - 根据各层节点初始化网络所有连接；

- train：迭代训练

    1. predict：遍历调用每 layer 的 calc_output()

    2. calc_delta：计算误差项

        - 遍历调用输出层节点的 calc_output_layer_delta
        - 遍历调用隐藏层节点的 calc_hidden_layer_delta

    3. update_weight：更新权重

        遍历连接 计算更新权重



#### 测试

```python
newwork = Network([input_count, hidden_count, output_count]) # 创建神经网络
while True:
	network,train(train_labels, train_data_set, study_rate, iteration_count) # 迭代训练
	if 条件成立:
		break;
```



